# =============================================================================
# AI BASICS - SPRING AI EDUCATIONAL APPLICATION
# =============================================================================
# This configuration file connects our Spring Boot app to an LLM provider.
# We use OpenAI-compatible APIs, which means you can use:
# - OpenAI directly (api.openai.com)
# - Azure OpenAI
# - Local models with OpenAI-compatible APIs (Ollama, LocalAI, etc.)
# =============================================================================

spring.application.name=ai-basics

# =============================================================================
# OPENAI API CONFIGURATION
# =============================================================================
# OPTION 1: Use Ollama (FREE - runs locally)
# Install: brew install ollama
# Pull models: ollama pull llama3.2:3b && ollama pull nomic-embed-text
# Start: ollama serve
spring.ai.openai.api-key=${OPENAI_API_KEY:ollama}
spring.ai.openai.base-url=${OPENAI_BASE_URL:http://localhost:11434}

# OPTION 2: Use OpenAI (requires payment - ~$5 minimum)
# Uncomment below and comment the Ollama lines above:
# spring.ai.openai.api-key=${OPENAI_API_KEY:your-key-here}
# spring.ai.openai.base-url=${OPENAI_BASE_URL:https://api.openai.com}

# =============================================================================
# CHAT MODEL CONFIGURATION
# =============================================================================
# For Ollama: llama3.2:3b (recommended), llama3.2:1b (faster), mistral, phi3
# For OpenAI: gpt-3.5-turbo, gpt-4o-mini, gpt-4o
spring.ai.openai.chat.options.model=${OPENAI_MODEL:llama3.2:3b}

# -----------------------------------------------------------------------------
# DEFAULT GENERATION PARAMETERS (can be overridden per request)
# These are the key parameters from your course!
# -----------------------------------------------------------------------------

# TEMPERATURE (0.0 - 2.0)
# Controls randomness/creativity in the output.
# - 0.0 = Deterministic (always picks the most probable token)
# - 0.7 = Balanced (default, good for most tasks)
# - 1.5+ = Very creative/random (may produce nonsense)
spring.ai.openai.chat.options.temperature=0.7

# TOP-P (Nucleus Sampling) (0.0 - 1.0)
# Considers only tokens whose cumulative probability reaches this threshold.
# - 0.1 = Very focused (only top 10% probability mass)
# - 0.9 = More diverse (top 90% probability mass)
# - 1.0 = Consider all tokens
spring.ai.openai.chat.options.top-p=1.0

# MAX TOKENS
# Maximum number of tokens in the generated response.
# Remember: tokens != words (roughly 1 token = 0.75 words in English)
spring.ai.openai.chat.options.max-tokens=1024

# =============================================================================
# EMBEDDING MODEL CONFIGURATION
# =============================================================================
# Embeddings convert text into numerical vectors that capture semantic meaning.
# These vectors enable similarity search and semantic understanding.
# For Ollama: nomic-embed-text (recommended), mxbai-embed-large, all-minilm
# For OpenAI: text-embedding-3-small, text-embedding-3-large
spring.ai.openai.embedding.options.model=${OPENAI_EMBEDDING_MODEL:nomic-embed-text}

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
server.port=8080
